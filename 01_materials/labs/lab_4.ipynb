{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gw8z-cN6QkcC"
      },
      "source": [
        "# Convolutions\n",
        "\n",
        "In this lab, we'll look in detail at convolutions and how they can be used to process images."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jBkHQnt2QkcE"
      },
      "source": [
        "### Reading and opening images\n",
        "\n",
        "We'll use the `skimage` library to read and process images. It's a library dedicated to image processing, which is part of the `scikit-learn` family."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# huggingface.co/models have a lot of pretrained models."
      ],
      "metadata": {
        "id": "yM76kiU_bYMB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check if the packages are installed, if not install them.\n",
        "# note - if you are working locally, you may want to comment this section out\n",
        "# and use your preferred method of installing packages\n",
        "import importlib\n",
        "\n",
        "def install_if_missing (package):\n",
        "  if importlib.util.find_spec(package) is None:\n",
        "    !pip_install (package)\n",
        "for package in [\"matplotlib\", \"numpy\", \"sklearn\", \"pandas\", \"tensorflow\", \"scikit-image\"]:\n",
        "  install_if_missing(package)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aTpfclNpSQDO",
        "outputId": "26fc9674-1123-44b1-bff8-da72fccedb04"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: -c: line 1: syntax error near unexpected token `package'\n",
            "/bin/bash: -c: line 1: `pip_install (package)'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "QDiQMUrbQkcG"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "from skimage.io import imread"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "QGcGwFZCQkcH"
      },
      "outputs": [],
      "source": [
        "# Helper function to download images from our GitHub repo\n",
        "\n",
        "def download_image(image_name):\n",
        "    url = \"https://raw.githubusercontent.com/UofT-DSI/deep_learning/main/notebooks/images/\" + image_name\n",
        "    import requests\n",
        "    r = requests.get(url)\n",
        "    with open(image_name, 'wb') as f:\n",
        "        f.write(r.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "XeIzq2C4QkcI",
        "outputId": "71fb0a6a-35d3-4920-b562-e7af1c0eed76"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample image shape:  (300, 451, 3)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'plt' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-706e4f736e72>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"sample image shape: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'uint8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
          ]
        }
      ],
      "source": [
        "from skimage import data\n",
        "sample_image = data.cat()\n",
        "#download_image(\"bumblebee.png\")\n",
        "#sample_image = imread(\"bumblebee.png\")\n",
        "sample_image= sample_image.astype(\"float32\")\n",
        "\n",
        "size = sample_image.shape\n",
        "print(\"sample image shape: \", sample_image.shape)\n",
        "\n",
        "plt.imshow(sample_image.astype('uint8'));"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZuagS-n0QkcI"
      },
      "source": [
        "### A simple convolution filter\n",
        "\n",
        "Before we start working on training any models, let's look at applying a convolution filter to an image. We'll use the `Conv2D` layer from Keras to do this."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "vm3Hcik8QkcI"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Conv2D"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zqdNP4APQkcJ",
        "outputId": "be488355-c187-4665-b409-8fd92a152bec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "conv = Conv2D(filters=3, kernel_size=(5, 5), padding=\"same\", # define how many filters we want to use, the kernal size\n",
        "              input_shape=(None, None, 3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "arVR3zLGQkcJ"
      },
      "source": [
        "Remember: in Keras, `None` is used as a marker for tensor dimensions with dynamic size. In this case `batch_size`, `width` and `height` are all dynamic: they can depend on the input. This is a neat feature of convolutional neural networks: the same model can be used to process images of any size, because all we have to do is slide the convolutional filter across the image as much as necessary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "tNic_v3oQkcK",
        "outputId": "a386f0ff-1685-455c-d581-4f6d3a3e0b01"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'sample_image' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-f71a7548ad00>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msample_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'sample_image' is not defined"
          ]
        }
      ],
      "source": [
        "sample_image.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5J_XkHpxQkcK"
      },
      "outputs": [],
      "source": [
        "img_in = np.expand_dims(sample_image, 0)\n",
        "img_in.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MP37Q_faQkcL"
      },
      "outputs": [],
      "source": [
        "img_out = conv(img_in) # Apply the convolutional filter\n",
        "\n",
        "# fit in the bee image as input and get filtered image out of it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B1y1bgRKQkcL"
      },
      "source": [
        "The output is a tensorflow Eager Tensor - a special data structure that is used to represent the result of operations in TensorFlow. It is not a numpy array, but it can be converted to one using the `.numpy()` method:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VI7G4nbNQkcM"
      },
      "outputs": [],
      "source": [
        "\n",
        "np_img_out = img_out[0].numpy()\n",
        "print(type(np_img_out))\n",
        "print(np_img_out.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1oxKRfy6QkcN"
      },
      "outputs": [],
      "source": [
        "# to see what the output looks like\n",
        "\n",
        "fig, (ax0, ax1) = plt.subplots(ncols=2, figsize=(10, 5))\n",
        "ax0.imshow(sample_image.astype('uint8'))\n",
        "ax1.imshow(np_img_out.astype('uint8'));"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bsNYYrhOQkcN"
      },
      "source": [
        "As we can see, our convolutional filter was initialized randomly, so our output doesn't contain any specific meaning. Each pixel is a random combination of the pixels in the input image, in a 5x5 window."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cs3D-aJ4QkcO"
      },
      "source": [
        "Let's instead take a look at a convolutional feature with a clear purpose. We can build a kernel ourselves, by defining a function which will be passed to `Conv2D` Layer.\n",
        "We'll create an array with 1/25 for filters, with each channel seperated. Before you move to the next cell, can you guess what this filter will do?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yc0aGKvAQkcO"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "# calculating avg values from RGB values\n",
        "# convolution of 5x5, blurring things - softening edges\n",
        "def my_kernel(shape=(5, 5, 3, 3), dtype=None):\n",
        "    array = np.zeros(shape=shape, dtype=\"float32\")\n",
        "    array[:, :, 0, 0] = 1 / 25\n",
        "    array[:, :, 1, 1] = 1 / 25\n",
        "    array[:, :, 2, 2] = 1 / 25\n",
        "    return array"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "1tGiwC7RQkcO"
      },
      "source": [
        "Now we can use this function to initialize a `Conv2D` layer:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "F90Vky3iQkcP"
      },
      "outputs": [],
      "source": [
        "conv = Conv2D(filters=3, kernel_size=(5, 5), padding=\"same\",\n",
        "           input_shape=(None, None, 3), kernel_initializer=my_kernel)\n",
        "# try different values to see what you get."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7DWNvPwTQkcS"
      },
      "outputs": [],
      "source": [
        "fig, (ax0, ax1) = plt.subplots(ncols=2, figsize=(10, 5))\n",
        "ax0.imshow(img_in[0].astype('uint8'))\n",
        "\n",
        "img_out = conv(img_in)\n",
        "np_img_out = img_out[0].numpy()\n",
        "ax1.imshow(np_img_out.astype('uint8'));\n",
        "\n",
        "# right side image is blurred."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QEBoC-EfQkcS"
      },
      "source": [
        "Hopefully you can tell what this filter does!\n",
        "\n",
        "**Exercise**\n",
        "- There are a number of settings when we define our Conv2D layer. Try changing the following parameters to get a sense of how they impact the result:\n",
        "- kernel_size: try different sizes\n",
        "- padding: try 'valid' instead of 'same' (hint: this may change the size of the output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kWxRczN_QkcT"
      },
      "outputs": [],
      "source": [
        "# Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aB371pMTQkcT"
      },
      "source": [
        "### Working on edge detection on Grayscale image\n",
        "\n",
        "Using a grayscale image, let's build an \"edge detector\" using a convolutional filter. Some filters pre-date the deep learning era and are still used today. For example, the Sobel filter is used to detect edges in images. These easy-to-compute filters were used in the early days of computer vision and are still useful now."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "FUQVrVw9QkcT"
      },
      "outputs": [],
      "source": [
        "# convert image to greyscale\n",
        "grey_sample_image = sample_image.mean(axis=2)\n",
        "\n",
        "# add the channel dimension even if it's only one channel so\n",
        "# to be consistent with Keras expectations.\n",
        "grey_sample_image = grey_sample_image[:, :, np.newaxis]\n",
        "\n",
        "# matplotlib does not like the extra dim for the color channel\n",
        "# when plotting gray-level images. Let's use squeeze:\n",
        "plt.imshow(np.squeeze(grey_sample_image.astype(np.uint8)),\n",
        "           cmap=plt.cm.gray);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-sLQsNbmQkcU"
      },
      "source": [
        "**Exercise**\n",
        "- Build an edge detector using `Conv2D` on greyscale image by defining the kernel inside `my_kernel`.\n",
        "- You may experiment with several kernels to find a way to detect edges. The following article contains specific examples of kernels that you can use:\n",
        "- https://en.wikipedia.org/wiki/Kernel_(image_processing)\n",
        "- Try different kernels and see the impact on the output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "N6qxxF3PQkcU",
        "outputId": "8d31271d-4d35-4576-deb7-6da71ff97519"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'grey_sample_image' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-af489850f9c9>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m               input_shape=(None, None, 1), kernel_initializer=my_kernel)\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mimg_in\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrey_sample_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Reshape into a batch of size 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mimg_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_in\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Apply the convolutional filter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mnp_img_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg_out\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Convert to numpy array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'grey_sample_image' is not defined"
          ]
        }
      ],
      "source": [
        "def my_kernel(shape=(3, 3, 1, 1), dtype=None):\n",
        "    array = np.array([[0, 0, 0],\n",
        "                      [0, 1, 0],\n",
        "                      [0, 0, 0]]) # Replace with your kernel\n",
        "    array = array.reshape(*shape) # Reshape if needed\n",
        "    return array\n",
        "\n",
        "conv = Conv2D(filters=1, kernel_size=(3, 3), padding=\"same\",\n",
        "              input_shape=(None, None, 1), kernel_initializer=my_kernel)\n",
        "\n",
        "# my kernel defined.\n",
        "\n",
        "img_in = np.expand_dims(grey_sample_image, 0) # Reshape into a batch of size 1\n",
        "# expand image to 4D dimensions.\n",
        "\n",
        "img_out = conv(img_in) # Apply the convolutional filter\n",
        "np_img_out = img_out[0].numpy() # Convert to numpy array\n",
        "\n",
        "fig, (ax0, ax1) = plt.subplots(ncols=2, figsize=(10, 5))\n",
        "ax0.imshow(np.squeeze(grey_sample_image.astype(np.uint8)),\n",
        "           cmap=plt.cm.gray)\n",
        "ax1.imshow(np_img_out.astype(np.uint8), cmap=plt.cm.gray);\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQdOcKqyQkcU"
      },
      "source": [
        "### Pooling and strides with convolutions\n",
        "\n",
        "**Exercise**\n",
        "- Use `MaxPool2D` to apply a 2x2 max pool with strides 2 to the image. What is the impact on the shape of the image?\n",
        "- Use `AvgPool2D` to apply an average pooling.\n",
        "- Is it possible to compute a max pooling and an average pooling with well chosen kernels?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kRQiI2twQkcV"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import MaxPool2D, AvgPool2D\n",
        "\n",
        "# You can use `img_in` from above as input to the pooling layers\n",
        "\n",
        "pool = MaxPool2D(pool_size=(2, 2), strides=2, padding = \"valid\") # decide on shape of filter used for pooling\n",
        "img_out = pool(img_in)\n",
        "\n",
        "np_img_out = img_out[0].numpy()\n",
        "print (np_img_out.shape)\n",
        "\n",
        "plt.imshow(np_img_out.astype('np.uint8')):\n",
        "\n",
        "\n",
        "\n",
        "#plt.imshow(np.squeeze(grey_sample_image.astype(np.uint8)),\n",
        "         #  cmap=plt.cm.gray);"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# anlternate solution - average pulling\n",
        "\n",
        "pool = AvgPool2D(pool_size=(2, 2), strides=2, padding = \"valid\") # decide on shape of filter used for pooling\n",
        "img_out = pool(img_in)\n",
        "\n",
        "np_img_out = img_out[0].numpy()\n",
        "print (np_img_out.shape)\n",
        "\n",
        "plt.imshow(np_img_out.astype('np.uint8')):\n",
        "\n",
        "\n",
        "# max vs avg pooling\n",
        "# max pooling chooses highest value in the receptive fields, captures highlights better\n",
        "# avg is blurring or softening the contrast.\n"
      ],
      "metadata": {
        "id": "sxluoZyYXc2c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "OKTLvgYxQkcV"
      },
      "source": [
        "## Loading a JPEG file as a numpy array\n",
        "\n",
        "Let's use [scikit-image](http://scikit-image.rg) to load the content of a JPEG file into a numpy array:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "6HHpN3LMQkcV",
        "outputId": "0c19ad72-5d65-4d0d-b87e-ea3c09b8748b"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'NoneType' object has no attribute 'ReadAsArray'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-43bd2e8f9119>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdownload_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'laptop.jpeg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'laptop.jpeg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/skimage/io/_io.py\u001b[0m in \u001b[0;36mimread\u001b[0;34m(fname, as_gray, plugin, **plugin_args)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mfile_or_url_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_plugin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'imread'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplugin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplugin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mplugin_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ndim'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/skimage/io/manage_plugins.py\u001b[0m in \u001b[0;36mcall_plugin\u001b[0;34m(kind, *args, **kwargs)\u001b[0m\n\u001b[1;32m    215\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Could not find the plugin \"{plugin}\" for {kind}.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/skimage/io/_plugins/imageio_plugin.py\u001b[0m in \u001b[0;36mimread\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimageio_imread\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimageio_imread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'WRITEABLE'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/imageio/v3.py\u001b[0m in \u001b[0;36mimread\u001b[0;34m(uri, index, plugin, extension, format_hint, **kwargs)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mimopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mplugin_kwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mimg_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mcall_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/imageio/core/legacy_plugin_wrapper.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, index, **kwargs)\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0mreader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_reader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mlegacy_get_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/imageio/core/format.py\u001b[0m in \u001b[0;36mget_data\u001b[0;34m(self, index, **kwargs)\u001b[0m\n\u001b[1;32m    433\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_BaseReaderWriter_last_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m                 \u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/imageio/plugins/gdal.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Gdal file contains only one dataset\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReadAsArray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_meta_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m_get_meta_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'ReadAsArray'"
          ]
        }
      ],
      "source": [
        "# some prebuilt things very good at handling image\n",
        "\n",
        "from skimage.io import imread\n",
        "\n",
        "download_image('laptop.jpeg')\n",
        "image = imread('laptop.jpeg')\n",
        "plt.imshow(image);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "LIuVb-jsQkcW"
      },
      "source": [
        "## Resizing images, handling data types and dynamic ranges\n",
        "\n",
        "While convolutions can handle inputs of any size, it is often useful to resize images to a fixed size. This is particularly important for training deep learning models:\n",
        "\n",
        "- for **image classification**, most networks expect a specific **fixed input size**;\n",
        "\n",
        "- for **object detection** and instance segmentation, networks have more flexibility but the image should have **approximately the same size as the training set images**.\n",
        "\n",
        "Furthermore **large images can be much slower to process** than smaller images (the number of pixels varies quadratically with the height and width)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GRVXAr57QkcW"
      },
      "outputs": [],
      "source": [
        "# also contains other fuctions\n",
        "# e.g. transform into lower resolution image.\n",
        "\n",
        "from skimage.transform import resize\n",
        "\n",
        "lowres_image = resize(image, (50, 50), mode='reflect', anti_aliasing=True)\n",
        "lowres_image.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ftyE4JGQkcW"
      },
      "outputs": [],
      "source": [
        "plt.imshow(lowres_image, interpolation='nearest');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "u9moJNX0QkcX"
      },
      "source": [
        "The values of the pixels of the low resolution image are computed from by combining the values of the pixels in the high resolution image. The result is therefore represented as floating points."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "lyClPx2vQkcX"
      },
      "source": [
        "## Using a pretrained model\n",
        "\n",
        "Objectives:\n",
        "\n",
        "- Load a pre-trained ResNet50 pre-trained model using Keras Zoo\n",
        "- Use the model to classify an image\n",
        "- Use the model to classify an image from the webcam\n",
        "\n",
        "Let's start with loading ResNet50, a well-established method for image classification. The ResNet50 \"application\" takes two key parameters here: firstly, `include_top` indicates whether we want to include the last layer of the network (the classification layer) or not. Secondly, `weights` indicates whether we want to load the weights of a model that has been pre-trained on ImageNet or not."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v14j4rECQkcY"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "\n",
        "model = ResNet50(include_top=True, weights='imagenet') # define your own resnet50,\n",
        "# define which weight you want to use, in this case use weights ppl already trained on imagenet.\n",
        "model.compile(optimizer='sgd', loss='categorical_crossentropy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IS4zqu_gQkcY"
      },
      "outputs": [],
      "source": [
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "hQn_MkhDQkcY"
      },
      "source": [
        "### Classification of an image\n",
        "\n",
        "**Exercise**\n",
        "- Reshape the `laptop` image to the shape `(224, 224, 3)` using `resize` from `skimage.transform`\n",
        "- Use `preprocess_input` from `tensorflow.keras.applications.imagenet_utils` to preprocess the image\n",
        "- Use `predict` to classify the image\n",
        "\n",
        "Documentation for each method:\n",
        "- [resize](https://scikit-image.org/docs/dev/api/skimage.transform.html#skimage.transform.resize)\n",
        "- [preprocess_input](https://www.tensorflow.org/api_docs/python/tf/keras/applications/resnet/preprocess_input)\n",
        "- [predict](https://www.tensorflow.org/api_docs/python/tf/keras/Model#predict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KaysdbS_Qkcg"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications.imagenet_utils import preprocess_input\n",
        "from tensorflow.keras.applications.imagenet_utils import decode_predictions\n",
        "\n",
        "# Your code here\n",
        "# send image to model and let model do classificaiton\n",
        "\n",
        "image_resized = resize(image, (224, 224), model = 'reflect', anti_aliasing = True) # * 256 # reshape to size the model accepts (?bug ,output format)\n",
        "image_resized = np.expand_dims (image_resized, 0)\n",
        "image_rezied = preprocess_input(image_resized)\n",
        "\n",
        "preds = model.predict(image_resized)\n",
        "print ('Predicte: ', decode_predictions(preds, top = 3)[0]) # gives you top 3 classes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "gKhlI2gIQkch"
      },
      "source": [
        "##  Taking snapshots from the webcam\n",
        "\n",
        "For this section, we will take an image from your laptop webcam and classify it. If you feel uncomfortable doing this section, you can skip it and use a photo of your choice from the web instead."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rI4Sv6TZQkci"
      },
      "outputs": [],
      "source": [
        "# screenshot of webcam\n",
        "\n",
        "import cv2\n",
        "\n",
        "def camera_grab(camera_id=0, fallback_filename=None):\n",
        "    camera = cv2.VideoCapture(camera_id)\n",
        "    try:\n",
        "        # take 10 consecutive snapshots to let the camera automatically tune\n",
        "        # itself and hope that the contrast and lighting of the last snapshot\n",
        "        # is good enough.\n",
        "        for i in range(10):\n",
        "            snapshot_ok, image = camera.read()\n",
        "        if snapshot_ok:\n",
        "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        else:\n",
        "            print(\"WARNING: could not access camera\")\n",
        "            if fallback_filename:\n",
        "                image = imread(fallback_filename)\n",
        "    finally:\n",
        "        camera.release()\n",
        "    return image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YovKayrIQkci"
      },
      "outputs": [],
      "source": [
        "image = camera_grab(camera_id=0, fallback_filename='laptop.jpeg')\n",
        "plt.imshow(image)\n",
        "print(\"dtype: {}, shape: {}, range: {}\".format(\n",
        "    image.dtype, image.shape, (image.min(), image.max())))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "image_resized = resize(image, (224, 224), model = 'reflect', anti_aliasing = True) # reshape to size the model accepts\n",
        "image_resized = np.expand_dims (image_resized, 0)\n",
        "image_rezied = preprocess_input(image_resized)\n",
        "\n",
        "preds = model.predict(image_resized)\n",
        "print ('Predicte: ', decode_predictions(preds, top = 3)[0]) # gives you top 3 classes."
      ],
      "metadata": {
        "id": "SeY3lhEga-Uj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "ixQRU6wxQkcj"
      },
      "source": [
        "### Exercise\n",
        "\n",
        "Apply the same preprocessing as before and classify the image. What are your results?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4IRQSWXDQkcj"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}